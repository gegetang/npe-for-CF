{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#メモ\" data-toc-modified-id=\"メモ-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>メモ</a></div><div class=\"lev2 toc-item\"><a href=\"#reference\" data-toc-modified-id=\"reference-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>reference</a></div><div class=\"lev2 toc-item\"><a href=\"#その他\" data-toc-modified-id=\"その他-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>その他</a></div><div class=\"lev1 toc-item\"><a href=\"#概要\" data-toc-modified-id=\"概要-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>概要</a></div><div class=\"lev1 toc-item\"><a href=\"#前処理\" data-toc-modified-id=\"前処理-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>前処理</a></div><div class=\"lev1 toc-item\"><a href=\"#モデル定義\" data-toc-modified-id=\"モデル定義-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>モデル定義</a></div><div class=\"lev2 toc-item\"><a href=\"#データが単一の場合\" data-toc-modified-id=\"データが単一の場合-41\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>データが単一の場合</a></div><div class=\"lev2 toc-item\"><a href=\"#入力データ（userid,-itemid,-label)-が複数与えられた場合\" data-toc-modified-id=\"入力データ（userid,-itemid,-label)-が複数与えられた場合-42\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>入力データ（userid, itemid, label) が複数与えられた場合</a></div><div class=\"lev2 toc-item\"><a href=\"#実行時引数として与えられるグラフを構築\" data-toc-modified-id=\"実行時引数として与えられるグラフを構築-43\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>実行時引数として与えられるグラフを構築</a></div><div class=\"lev2 toc-item\"><a href=\"#クラスとして上記の機能をまとめる\" data-toc-modified-id=\"クラスとして上記の機能をまとめる-44\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>クラスとして上記の機能をまとめる</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# メモ\n",
    "\n",
    "Implementation of Neural Personalized Embedding for Collaborative Filtering\n",
    "(,arxiv, 2018/05/17)\n",
    "source paper: https://arxiv.org/abs/1805.06563\n",
    "\n",
    "## reference\n",
    "\n",
    "https://www.tensorflow.org/tutorials/word2vec \n",
    "\n",
    "https://www.comp.nus.edu.sg/~xiangnan/papers/ncf.pdf \n",
    "\n",
    "https://github.com/hexiangnan/neural_collaborative_filtering \n",
    "\n",
    "\n",
    "## その他\n",
    "\n",
    "* training 時の c_u_i は時系列を考慮しているわけではない？？？\n",
    "  * timestamp あるけど、無視してるようだし、実質未来の情報使ってるよね？\n",
    "  * 時系列順に何かできたら面白そう？\n",
    "  * あ\n",
    "* user embedding を他（プロフィール情報等）から作った方が良い？\n",
    "  * 新規ユーザーに対して本当にちゃんと動くのか？？？\n",
    "  * 要確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 概要\n",
    "\n",
    "movie-lens 100k に対して npe を試してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_origin = pd.read_csv(\n",
    "    \"./input/ml-100k/u.data\",\n",
    "    sep=\"\\t\",\n",
    "    names=[\"userid\", \"itemid\", \"rating\", \"timestamp\"],\n",
    "    usecols=[\"userid\", \"itemid\", \"rating\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_origin.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation(df):\n",
    "    df_new = df.copy()\n",
    "    df_new[\"rating\"] = (df_new[\"rating\"] > 3).astype(int)\n",
    "    \n",
    "    return df_new\n",
    "\n",
    "df_new = data_preparation(df)\n",
    "display(df_new.head(10))\n",
    "display(df_new[\"rating\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user や item の種類を確認\n",
    "count_user = max(df[\"userid\"])\n",
    "count_item = max(df[\"itemid\"])\n",
    "N = 4  # number of negative samples per positive example(for movie-lens 10m data)\n",
    "N = 1  # \n",
    "user_item_mtx = np.zeros((count_user, count_item))\n",
    "print(\"make user_item_mtx\")\n",
    "\n",
    "# train, valid, test にデータを分割\n",
    "# 学習用 user_item_mtx を作成\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル定義"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データが単一の場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 事前定義パラメータ\n",
    "num_users = 10\n",
    "num_items = 5\n",
    "dim_emb = 15\n",
    "SEED = 10\n",
    "\n",
    "tf.set_random_seed(SEED)\n",
    "\n",
    "# 実行時に与える引数（プレースホルダー）\n",
    "## user_item 行列、\n",
    "R = np.random.randint(0, 2, num_users*num_items).reshape((num_users, num_items))\n",
    "R = tf.constant(R, dtype=tf.float32)\n",
    "# R = tf.placeholder(tf.int8, shape=[num_users, num_items])\n",
    "# user = tf.placeholder(tf.int32, shape=[])  # one hot\n",
    "# item = tf.placeholder(tf.int32, shape=[])\n",
    "# モデルに入れる前に one-hot にした方がスマート\n",
    "\n",
    "userid = 1\n",
    "itemid = 2\n",
    "\n",
    "# 学習対象パラメータの定義\n",
    "emb_user = tf.Variable(tf.random_normal(shape=[num_users, dim_emb]))\n",
    "emb_item = tf.Variable(tf.random_normal(shape=[num_items, dim_emb]))\n",
    "item_context = tf.Variable(tf.random_normal(shape=[num_items, dim_emb]))\n",
    "\n",
    "# one-hot に変換\n",
    "x_u = tf.one_hot([userid - 1], depth=num_users, dtype=tf.float32)\n",
    "x_u = tf.reshape(x_u, [num_users, 1])\n",
    "y_i = tf.one_hot([itemid - 1], depth=num_items, dtype=tf.float32)\n",
    "y_i = tf.reshape(y_i, [num_items, 1])\n",
    "\n",
    "# 活性化関数\n",
    "h_u = tf.matmul(tf.transpose(x_u), emb_user)\n",
    "h_u = tf.nn.relu(h_u)\n",
    "w_i = tf.matmul(tf.transpose(y_i), emb_item)\n",
    "w_i = tf.nn.relu(w_i)\n",
    "# c_ui: the set of iterms that user u clicked, excluding i\n",
    "r_u = tf.reshape(R[userid], [num_items, 1])\n",
    "c_ui = tf.subtract(r_u, y_i)  # [0] for matrix -> vector\n",
    "v_c_ui = tf.matmul(tf.transpose(c_ui), item_context)\n",
    "v_c_ui = tf.nn.relu(v_c_ui)\n",
    "\n",
    "# 内積\n",
    "r_1 = tf.matmul(h_u, tf.transpose(w_i))\n",
    "r_2 = tf.matmul(w_i, tf.transpose(v_c_ui))\n",
    "rate_pred = tf.nn.sigmoid(tf.add(r_1, r_2))\n",
    "\n",
    "# 損失関数\n",
    "# binary cross entropy ???\n",
    "# 将来的にはミニバッチに適用できるようにする？\n",
    "bce = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "    labels=R[userid][itemid],\n",
    "    logits=rate_pred[0][0]\n",
    ")\n",
    "\n",
    "# Optimize\n",
    "optimizer = tf.train.AdamOptimizer(0.001)\n",
    "train = optimizer.minimize(bce)\n",
    "\n",
    "# initializer\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for i in range(1000):\n",
    "        sess.run(train)\n",
    "        if i % 50 == 0:\n",
    "            print(\"i: \", i, \"bce: \", bce.eval())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 入力データ（userid, itemid, label) が複数与えられた場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 事前定義パラメータ\n",
    "num_users = 10\n",
    "num_items = 5\n",
    "dim_emb = 15\n",
    "epoch = 50\n",
    "SEED = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "tf.set_random_seed(SEED)\n",
    "\n",
    "# 入力データを適当に作る\n",
    "R = np.random.randint(0, 2, num_users*num_items).reshape((num_users, num_items))\n",
    "userids = [i for i in range(num_users) for j in range(num_items)]\n",
    "itemids = [j for i in range(num_users) for j in range(num_items)]\n",
    "labels = [R[i][j] for i in range(num_users) for j in range(num_items)]\n",
    "userids = np.array(userids)\n",
    "itemids = np.array(itemids)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# 実行時引数\n",
    "# 入力として与えられる\n",
    "# 後でプレースホルダ―で定義する\n",
    "# R, userids, itemids, label\n",
    "# place holder で次元を指定したくない場合はどうする？\n",
    "R = tf.constant(R, dtype=tf.float32)\n",
    "userids = tf.constant(userids, dtype=tf.int32)\n",
    "itemids = tf.constant(itemids, dtype=tf.int32)\n",
    "labels = tf.constant(labels, dtype=tf.float32)\n",
    "\n",
    "# 学習対象パラメータの定義\n",
    "emb_user = tf.Variable(tf.random_normal(shape=[num_users, dim_emb]))\n",
    "emb_item = tf.Variable(tf.random_normal(shape=[num_items, dim_emb]))\n",
    "emb_context_item = tf.Variable(tf.random_normal(shape=[num_items, dim_emb]))\n",
    "\n",
    "# 学習データ内の userid, itemid をそれぞれ one-hot に変換\n",
    "userids_onehot = tf.one_hot(userids, depth=num_users, dtype=tf.float32)\n",
    "userids_onehot = tf.reshape(userids_onehot, [-1, num_users])\n",
    "itemids_onehot = tf.one_hot(itemids, depth=num_items, dtype=tf.float32)\n",
    "itemids_onehot = tf.reshape(itemids_onehot, [-1, num_items])\n",
    "\n",
    "# 訓練データ内の userids を埋め込みベクトルに変換\n",
    "h = tf.nn.relu(tf.nn.embedding_lookup(emb_user, userids))\n",
    "\n",
    "# 訓練データ内の itemids を埋め込みベクトルに変換\n",
    "w = tf.nn.relu(tf.nn.embedding_lookup(emb_item, itemids))\n",
    "\n",
    "# コンテキスト（履歴）、userids における各ユーザーがクリックしたアイテム一覧\n",
    "# ただし i は除く\n",
    "# 訓練データの各 (userid, itemid) に対応している\n",
    "context = tf.subtract(tf.matmul(userids_onehot, R), itemids_onehot)\n",
    "\n",
    "# コンテキスト埋め込みベクトルに変換して relu 通す\n",
    "v = tf.nn.relu(tf.matmul(context, emb_context_item))\n",
    "\n",
    "# 各データに対応する内積値\n",
    "# (訓練データ数, 1) になる予定\n",
    "r_1 = tf.reduce_sum(tf.multiply(h, w), axis=1)\n",
    "r_2 = tf.reduce_sum(tf.multiply(w, v), axis=1)\n",
    "\n",
    "# 予測値(訓練データ数個ある予定)\n",
    "# predicts = tf.nn.sigmoid(r)\n",
    "# 訓練する上では下記の tf.nn.sigmoid_cross... を使うため predicts は求めない\n",
    "r = tf.add(r_1, r_2)\n",
    "\n",
    "# loss: binary cross entropy\n",
    "bce = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "    labels=labels,\n",
    "    logits=r\n",
    ")\n",
    "loss = tf.reduce_sum(bce)\n",
    "\n",
    "# Optimize\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for i in range(epoch):\n",
    "        sess.run(train)\n",
    "        l = sess.run(loss)\n",
    "        if i % 5 == 0:\n",
    "            print(\"Iteration: \", i, \"Loss: \", l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実行時引数として与えられるグラフを構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 事前定義パラメータ\n",
    "num_users = 10\n",
    "num_items = 5\n",
    "dim_emb = 15\n",
    "epoch = 50\n",
    "SEED = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "tf.set_random_seed(SEED)\n",
    "\n",
    "# 入力データを適当に作る\n",
    "input_R = np.random.randint(0, 2, num_users*num_items).reshape((num_users, num_items))\n",
    "input_userids = np.array([i for i in range(num_users) for j in range(num_items)])\n",
    "input_itemids = np.array([j for i in range(num_users) for j in range(num_items)])\n",
    "input_labels = np.array([input_R[i][j] for i in range(num_users) for j in range(num_items)])\n",
    "\n",
    "# place holder 設定\n",
    "# R は事前に与えるべき？\n",
    "# たしかにバッチのたびに与えるのは何か違うような…でも定数だしありか？\n",
    "# 一旦毎回与える方式で\n",
    "R = tf.placeholder(tf.float32, shape=[None, None])\n",
    "userids = tf.placeholder(tf.int32)\n",
    "itemids = tf.placeholder(tf.int32)\n",
    "labels = tf.placeholder(tf.float32)\n",
    "\n",
    "# 学習対象パラメータの定義\n",
    "emb_user = tf.Variable(tf.random_normal(shape=[num_users, dim_emb]))\n",
    "emb_item = tf.Variable(tf.random_normal(shape=[num_items, dim_emb]))\n",
    "emb_context_item = tf.Variable(tf.random_normal(shape=[num_items, dim_emb]))\n",
    "\n",
    "# 学習データ内の userid, itemid をそれぞれ one-hot に変換\n",
    "userids_onehot = tf.one_hot(userids, depth=num_users, dtype=tf.float32)\n",
    "userids_onehot = tf.reshape(userids_onehot, [-1, num_users])\n",
    "itemids_onehot = tf.one_hot(itemids, depth=num_items, dtype=tf.float32)\n",
    "itemids_onehot = tf.reshape(itemids_onehot, [-1, num_items])\n",
    "\n",
    "# 訓練データ内の userids を埋め込みベクトルに変換\n",
    "h = tf.nn.relu(tf.nn.embedding_lookup(emb_user, userids))\n",
    "\n",
    "# 訓練データ内の itemids を埋め込みベクトルに変換\n",
    "w = tf.nn.relu(tf.nn.embedding_lookup(emb_item, itemids))\n",
    "\n",
    "# コンテキスト（履歴）、userids における各ユーザーがクリックしたアイテム一覧\n",
    "# ただし i は除く\n",
    "# 訓練データの各 (userid, itemid) に対応している\n",
    "context = tf.subtract(tf.matmul(userids_onehot, R), itemids_onehot)\n",
    "\n",
    "# コンテキスト埋め込みベクトルに変換して relu 通す\n",
    "v = tf.nn.relu(tf.matmul(context, emb_context_item))\n",
    "\n",
    "# 各データに対応する内積値\n",
    "# (訓練データ数, 1) になる予定\n",
    "r_1 = tf.reduce_sum(tf.multiply(h, w), axis=1)\n",
    "r_2 = tf.reduce_sum(tf.multiply(w, v), axis=1)\n",
    "\n",
    "# 予測値(訓練データ数個ある予定)\n",
    "# predicts = tf.nn.sigmoid(r)\n",
    "# 訓練する上では下記の tf.nn.sigmoid_cross... を使うため predicts は求めない\n",
    "r = tf.add(r_1, r_2)\n",
    "\n",
    "# loss: binary cross entropy\n",
    "bce = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "    labels=labels,\n",
    "    logits=r\n",
    ")\n",
    "loss = tf.reduce_sum(bce)\n",
    "\n",
    "# Optimize\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for i in range(epoch):\n",
    "        sess.run(train, \n",
    "                 feed_dict={R: input_R, userids: input_userids, \n",
    "                            itemids: input_itemids, labels: input_labels})\n",
    "        x = sess.run(loss, \n",
    "                 feed_dict={R: input_R, userids: input_userids, \n",
    "                            itemids: input_itemids, labels: input_labels})\n",
    "    # モデルの保存的なこともここで行う？\n",
    "    \n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## クラスとして上記の機能をまとめる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph build!\n",
      "loss:  112.416\n",
      "loss:  110.913\n",
      "loss:  109.426\n",
      "loss:  107.955\n",
      "loss:  106.524\n",
      "loss:  105.117\n",
      "loss:  103.727\n",
      "loss:  102.357\n",
      "loss:  101.009\n",
      "loss:  99.6925\n",
      "loss:  98.3972\n",
      "loss:  97.147\n",
      "loss:  95.9417\n",
      "loss:  94.7551\n",
      "loss:  93.5833\n",
      "loss:  92.4306\n",
      "loss:  91.2944\n",
      "loss:  90.1726\n",
      "loss:  89.0691\n",
      "loss:  87.9896\n",
      "[ 0.99420553]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "options = {\n",
    "    \"num_users\": 10,\n",
    "    \"num_items\": 5,\n",
    "    \"dim_emb\": 15,\n",
    "    \"seed\": 10,\n",
    "    \"learning_rate\": 0.001\n",
    "}\n",
    "\n",
    "\n",
    "class NeuralPersonalizedEmbedding(object):\n",
    "    def __init__(self, options, session):\n",
    "        self._session = session\n",
    "        self._num_users = options[\"num_users\"]\n",
    "        self._num_items = options[\"num_items\"]\n",
    "        self._dim_emb = options[\"dim_emb\"]\n",
    "        self._learning_rate = options[\"learning_rate\"]\n",
    "        self.build_graph()\n",
    "\n",
    "    def build_graph(self):\n",
    "        # place holder 設定\n",
    "        # R は事前に与えるべき？\n",
    "        # たしかにバッチのたびに与えるのは何か違うような…でも定数だしありか？\n",
    "        # 一旦毎回与える方式で\n",
    "        R = tf.placeholder(tf.float32, shape=[None, None])\n",
    "        userids = tf.placeholder(tf.int32)\n",
    "        itemids = tf.placeholder(tf.int32)\n",
    "        labels = tf.placeholder(tf.float32)\n",
    "        self._R = R\n",
    "        self._userids = userids\n",
    "        self._itemids = itemids\n",
    "        self._labels = labels\n",
    "\n",
    "        # 学習対象パラメータの定義\n",
    "        emb_user = tf.Variable(\n",
    "            tf.random_normal(shape=[self._num_users, self._dim_emb]))\n",
    "        emb_item = tf.Variable(\n",
    "            tf.random_normal(shape=[self._num_items, self._dim_emb]))\n",
    "        emb_context_item = tf.Variable(\n",
    "            tf.random_normal(shape=[self._num_items, self._dim_emb]))\n",
    "\n",
    "        # 学習データ内の userid, itemid をそれぞれ one-hot に変換\n",
    "        userids_onehot = tf.one_hot(userids, depth=self._num_users, dtype=tf.float32)\n",
    "        userids_onehot = tf.reshape(userids_onehot, [-1, self._num_users])\n",
    "        itemids_onehot = tf.one_hot(itemids, depth=self._num_items, dtype=tf.float32)\n",
    "        itemids_onehot = tf.reshape(itemids_onehot, [-1, self._num_items])\n",
    "\n",
    "        # 訓練データ内の userids を埋め込みベクトルに変換\n",
    "        h = tf.nn.relu(tf.nn.embedding_lookup(emb_user, userids))\n",
    "\n",
    "        # 訓練データ内の itemids を埋め込みベクトルに変換\n",
    "        w = tf.nn.relu(tf.nn.embedding_lookup(emb_item, itemids))\n",
    "\n",
    "        # コンテキスト（履歴）、userids における各ユーザーがクリックしたアイテム一覧\n",
    "        # ただし i は除く\n",
    "        # 訓練データの各 (userid, itemid) に対応している\n",
    "        context = tf.subtract(tf.matmul(userids_onehot, R), itemids_onehot)\n",
    "\n",
    "        # コンテキスト埋め込みベクトルに変換して relu 通す\n",
    "        v = tf.nn.relu(tf.matmul(context, emb_context_item))\n",
    "\n",
    "        # 各データに対応する内積値\n",
    "        # (訓練データ数, 1) になる予定\n",
    "        r_1 = tf.reduce_sum(tf.multiply(h, w), axis=1)\n",
    "        r_2 = tf.reduce_sum(tf.multiply(w, v), axis=1)\n",
    "\n",
    "        # 訓練する上では下記の tf.nn.sigmoid_cross... を使うため predicts は学習時\n",
    "        # は求めない\n",
    "        r = tf.add(r_1, r_2)\n",
    "\n",
    "        # 予測値(訓練データ数個ある予定)\n",
    "        predicts = tf.nn.sigmoid(r)\n",
    "        self._predictop = predicts\n",
    "\n",
    "        # loss: binary cross entropy\n",
    "        bce = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=labels,\n",
    "            logits=r\n",
    "        )\n",
    "        loss = tf.reduce_sum(bce)\n",
    "        self._lossop = loss\n",
    "\n",
    "        # Optimize\n",
    "        optimizer = tf.train.AdamOptimizer(self._learning_rate)\n",
    "        train = optimizer.minimize(loss)\n",
    "\n",
    "        # trainer and saver\n",
    "        self._trainop = train\n",
    "        tf.global_variables_initializer().run()\n",
    "        self.saver = tf.train.Saver()\n",
    "        print(\"graph build!\")\n",
    "\n",
    "    def train(self, user_item_mtx, userids, itemids, labels):\n",
    "        self._session.run(\n",
    "            self._trainop,\n",
    "            feed_dict={\n",
    "                self._R: user_item_mtx, self._userids: userids, \n",
    "                self._itemids: itemids, self._labels: labels\n",
    "            }\n",
    "        )\n",
    "        self._loss = self._session.run(\n",
    "            self._lossop,\n",
    "            feed_dict={\n",
    "                self._R: user_item_mtx, self._userids: userids, \n",
    "                self._itemids: itemids, self._labels: labels\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def predict(self, user_item_mtx, userids, itemids):\n",
    "        predicts = self._session.run(\n",
    "            self._predictop,\n",
    "            feed_dict={\n",
    "                self._R: user_item_mtx, self._userids: userids, \n",
    "                self._itemids: itemids\n",
    "            }\n",
    "        )\n",
    "        return predicts\n",
    "\n",
    "    def print_loss(self):\n",
    "        print(\"loss: \", self._loss)\n",
    "\n",
    "    def get_loss(self):\n",
    "        return self._loss\n",
    "\n",
    "    def save(self, session, path):\n",
    "        self._saver.save(session, path)\n",
    "        print(\"model saved!\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # args = parse_args()\n",
    "    epoch = 100\n",
    "    # training\n",
    "    num_users = 10\n",
    "    num_items = 5\n",
    "    dim_emb = 15\n",
    "    input_R = np.random.randint(0, 2, num_users*num_items).reshape((num_users, num_items))\n",
    "    input_userids = np.array([i for i in range(num_users) for j in range(num_items)])\n",
    "    input_itemids = np.array([j for i in range(num_users) for j in range(num_items)])\n",
    "    input_labels = np.array([input_R[i][j] for i in range(num_users) for j in range(num_items)])\n",
    "\n",
    "    # データをロード\n",
    "    \n",
    "\n",
    "    with tf.Graph().as_default(), tf.Session() as session:\n",
    "        model = NeuralPersonalizedEmbedding(options, session)\n",
    "        for i in range(epoch):\n",
    "            model.train(input_R, input_userids, input_itemids, input_labels)\n",
    "            if i % 5 == 0:\n",
    "                model.print_loss()\n",
    "        print(model.predict(input_R, [3], [3]))\n",
    "        print(input_R[3][3])\n",
    "        #    model.eval()  # loss の表示\n",
    "        #model.save(session, \"./mymodel_20180601.ckpt\")\n",
    "\n",
    "\n",
    "def train_minibatch():\n",
    "    return None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 動作させてみる\n",
    "npe = neural_personalized_embedding_cf()\n",
    "# npe.leaning(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 予測してみる\n",
    "\n",
    "\n",
    "# 精度を確認してみる"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "215px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "831px",
    "left": "0px",
    "right": "901px",
    "top": "107px",
    "width": "26px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
